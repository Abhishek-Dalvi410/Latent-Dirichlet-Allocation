{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import math\n",
    "from scipy.special import digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['eat turkey on turkey day holiday',\n",
    "          'i like to eat cake on holiday',\n",
    "          'turkey trot race on thanksgiving holiday',\n",
    "          'snail race the turtle',\n",
    "          'time travel space race',\n",
    "          'movie on thanksgiving',\n",
    "          'movie at air and space museum is cool movie',\n",
    "          'aspiring movie star']\n",
    "\n",
    "# corpus = ['bayesian or frequentist ML',\n",
    "#           'bayesian statistics probability math',\n",
    "#           'probability theory ML',\n",
    "#           'frequentist statistics math',\n",
    "#           'time travel space race',\n",
    "#           'movie on thanksgiving space',\n",
    "#           'movie at air and space museum is cool movie',\n",
    "#           'aspiring movie star time']\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(topics):\n",
    "    K = topics # number of topics\n",
    "    M = 8 # number of documents\n",
    "    V = len(vectorizer.vocabulary_) # vocab size\n",
    "    alphas = np.ones(M)*0.01\n",
    "    gamma = np.zeros((M,K))\n",
    "    \n",
    "    for i in range(K):\n",
    "        gamma[:,i]= alphas\n",
    "        \n",
    "    #beta = np.ones((V,K)) * 1/K\n",
    "    \n",
    "    beta = np.random.rand(V,K)\n",
    "    bnormalizer = np.sum(beta, axis=0)\n",
    "    for i in range(beta.shape[0]):\n",
    "        beta[i] = beta[i]/bnormalizer\n",
    "    \n",
    "\n",
    "    return K,M,V,gamma,beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-6229e034f5f3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-6229e034f5f3>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    likelihood += math.log(math.gamma(alpha)) + (alpha-1)*\u001b[0m\n\u001b[1;37m                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def log_likelihood(M, N, K, gamma, beta, alpha=0.01):\n",
    "    \n",
    "    likelihood = math.log(math.gamma(alpha*K))\n",
    "    \n",
    "    for i in range(K):\n",
    "        likelihood += math.log(math.gamma(alpha)) + (alpha-1)*\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(M, N, K, old_gamma, beta1):\n",
    "    \n",
    "    support = np.zeros(M) # support for each doccuemnt\n",
    "    for d in range(M):\n",
    "        for n in range(N):\n",
    "            if docs[d][n] ==0:\n",
    "                continue\n",
    "            support[d] = support[d]+1\n",
    "    \n",
    "    ss_beta = np.zeros((V,K)) \n",
    "    for d in range(M):\n",
    "        #repaet til convergence\n",
    "        for _ in range(100):\n",
    "            gamma = np.ones(K) * 0.01 # 0.01 is alpha\n",
    "            for n in range(N):\n",
    "                if docs[d][n] !=0:\n",
    "                    local_phi = np.zeros(K)\n",
    "                    normalizer = 0\n",
    "                    for i in range(K):\n",
    "                        local_phi[i] = beta1[n][i] * math.exp(digamma(old_gamma[d][i]))\n",
    "                        normalizer = normalizer + local_phi[i]\n",
    "\n",
    "                    local_phi = local_phi / normalizer\n",
    "                    ss_beta[n,:] += local_phi * docs[d][n]\n",
    "                    gamma = gamma + local_phi * docs[d][n]\n",
    "            old_gamma[d] = gamma\n",
    "        \n",
    "    return old_gamma, ss_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(ss_beta, beta):\n",
    "    for i in range(K):\n",
    "        for j in range(V):\n",
    "            beta[j][i] = ss_beta[j][i]\n",
    "            \n",
    "    normlizer = np.sum(beta, axis=0)\n",
    "    beta = beta/normlizer\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K,M,V,gamma,beta = initialize(topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma, ss_beta = E_step(M, V, K, gamma, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = M_step(ss_beta, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.94156656e-223, 1.00000000e+002],\n",
       "       [5.35630376e-223, 1.00000000e+002],\n",
       "       [3.36779344e-222, 1.00000000e+002],\n",
       "       [3.21320194e-223, 1.00000000e+002],\n",
       "       [2.37697851e-222, 1.00000000e+002],\n",
       "       [2.46434325e-222, 1.00000000e+002],\n",
       "       [1.00000000e+002, 2.26445789e-222],\n",
       "       [1.00000000e+002, 1.00000000e+002],\n",
       "       [2.00000000e+002, 1.00000000e+002],\n",
       "       [1.23800613e-222, 1.00000000e+002],\n",
       "       [1.97068355e-222, 1.00000000e+002],\n",
       "       [1.54701158e-221, 4.00000000e+002],\n",
       "       [1.03135444e-222, 1.00000000e+002],\n",
       "       [2.00000000e+002, 2.00000000e+002],\n",
       "       [3.00000000e+002, 3.46423167e-221],\n",
       "       [1.00000000e+002, 1.51513927e-221],\n",
       "       [1.00000000e+002, 1.00000000e+002],\n",
       "       [4.57069538e-221, 1.00000000e+002],\n",
       "       [1.00000000e+002, 1.00000000e+002],\n",
       "       [1.00000000e+002, 1.23216744e-221],\n",
       "       [1.00000000e+002, 3.95620497e-222],\n",
       "       [1.37592370e-222, 1.00000000e+002],\n",
       "       [1.00000000e+002, 2.01169048e-222],\n",
       "       [1.00000000e+002, 5.20266341e-222],\n",
       "       [3.00000000e+002, 4.13258857e-222],\n",
       "       [1.00000000e+002, 6.55310828e-222]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.47078328e-226, 4.76190476e-002],\n",
       "       [2.67815188e-226, 4.76190476e-002],\n",
       "       [1.68389672e-225, 4.76190476e-002],\n",
       "       [1.60660097e-226, 4.76190476e-002],\n",
       "       [1.18848925e-225, 4.76190476e-002],\n",
       "       [1.23217162e-225, 4.76190476e-002],\n",
       "       [5.00000000e-002, 1.07831328e-225],\n",
       "       [5.00000000e-002, 4.76190476e-002],\n",
       "       [1.00000000e-001, 4.76190476e-002],\n",
       "       [6.19003063e-226, 4.76190476e-002],\n",
       "       [9.85341773e-226, 4.76190476e-002],\n",
       "       [7.73505791e-225, 1.90476190e-001],\n",
       "       [5.15677220e-226, 4.76190476e-002],\n",
       "       [1.00000000e-001, 9.52380952e-002],\n",
       "       [1.50000000e-001, 1.64963413e-224],\n",
       "       [5.00000000e-002, 7.21494891e-225],\n",
       "       [5.00000000e-002, 4.76190476e-002],\n",
       "       [2.28534769e-224, 4.76190476e-002],\n",
       "       [5.00000000e-002, 4.76190476e-002],\n",
       "       [5.00000000e-002, 5.86746402e-225],\n",
       "       [5.00000000e-002, 1.88390713e-225],\n",
       "       [6.87961852e-226, 4.76190476e-002],\n",
       "       [5.00000000e-002, 9.57947846e-226],\n",
       "       [5.00000000e-002, 2.47745877e-225],\n",
       "       [1.50000000e-001, 1.96789932e-225],\n",
       "       [5.00000000e-002, 3.12052775e-225]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
